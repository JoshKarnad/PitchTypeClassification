{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Picked only a couple of params, would do more with more time\n",
    "rfc_params = {'n_estimators' : [5, 10], 'max_depth' : [5, None], 'random_state' : [12]}\n",
    "ridge_params = {'alpha' : [1, 2], 'max_iter' : [5, None], 'random_state' :[12]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.4, random_state = 12)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['pitch_type'])]\n",
    "Y_train = df_train['pitch_type']\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['pitch_type'])]\n",
    "Y_test = df_test['pitch_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 10, 'random_state': 12}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search RFC\n",
    "rfc = RandomForestClassifier()\n",
    "GSrfc = GridSearchCV(rfc, rfc_params)\n",
    "GSrfc.fit(X_train, Y_train)\n",
    "GSrfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'max_iter': 5, 'random_state': 12}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search Ridge\n",
    "ridge = RidgeClassifier()\n",
    "GSridge = GridSearchCV(ridge, ridge_params)\n",
    "GSridge.fit(X_train, Y_train)\n",
    "GSridge.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=12, verbose=0, warm_start=False)\n",
      "Accuracy: 0.458205522364\n",
      "F1 Macro: 0.385150027065\n",
      "F1 Micro: 0.458205522364\n",
      "F1 Weighted: 0.442751631981\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CH       0.27      0.22      0.25     43569\n",
      "         CU       0.29      0.24      0.26     33759\n",
      "         EP       0.08      0.01      0.02        84\n",
      "         FA       0.51      0.64      0.57    143423\n",
      "         FC       0.42      0.35      0.38     24964\n",
      "         FS       0.34      0.22      0.26      6297\n",
      "         FT       0.43      0.39      0.41     48718\n",
      "         IN       0.95      0.69      0.80      2417\n",
      "         KC       0.35      0.20      0.26      5123\n",
      "         KN       0.84      0.94      0.88      2666\n",
      "         PO       0.42      0.12      0.18       539\n",
      "         SC       0.36      0.14      0.20        73\n",
      "         SI       0.56      0.68      0.61     52506\n",
      "         SL       0.39      0.26      0.32     65859\n",
      "\n",
      "avg / total       0.44      0.46      0.44    429997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestrfc = RandomForestClassifier(max_depth= None, n_estimators= 10, random_state= 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarkarnad/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier(alpha=1, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=5, normalize=False, random_state=12, solver='auto',\n",
      "        tol=0.001)\n",
      "Accuracy: 0.482940578655\n",
      "F1 Macro: 0.325988761639\n",
      "F1 Micro: 0.482940578655\n",
      "F1 Weighted: 0.421518378768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CH       0.34      0.06      0.10     43569\n",
      "         CU       0.40      0.07      0.12     33759\n",
      "         EP       0.00      0.00      0.00        84\n",
      "         FA       0.49      0.79      0.60    143423\n",
      "         FC       0.48      0.31      0.38     24964\n",
      "         FS       0.38      0.06      0.11      6297\n",
      "         FT       0.43      0.42      0.42     48718\n",
      "         IN       1.00      0.70      0.82      2417\n",
      "         KC       0.47      0.07      0.13      5123\n",
      "         KN       0.80      1.00      0.89      2666\n",
      "         PO       0.00      0.00      0.00       539\n",
      "         SC       0.31      0.05      0.09        73\n",
      "         SI       0.52      0.84      0.64     52506\n",
      "         SL       0.44      0.19      0.26     65859\n",
      "\n",
      "avg / total       0.46      0.48      0.42    429997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarkarnad/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "bestridge = RidgeClassifier(alpha=1, max_iter = 5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model I am choosing is Ridge Classifier due to the higher scores across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_metrics(model, x_train, y_train, x_test, y_test):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    macro = f1_score(y_test, y_pred, average='macro')\n",
    "    micro = f1_score(y_test, y_pred, average='micro')\n",
    "    weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(model)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('F1 Macro:', macro)\n",
    "    print('F1 Micro:', micro)\n",
    "    print('F1 Weighted:', weighted)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarkarnad/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier(alpha=1, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=5, normalize=False, random_state=12, solver='auto',\n",
      "        tol=0.001)\n",
      "Accuracy: 0.482242338618\n",
      "F1 Macro: 0.337087704611\n",
      "F1 Micro: 0.482242338618\n",
      "F1 Weighted: 0.421574728665\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CH       0.35      0.06      0.11     29072\n",
      "         CU       0.41      0.07      0.12     22620\n",
      "         EP       0.00      0.00      0.00        50\n",
      "         FA       0.48      0.78      0.60     95322\n",
      "         FC       0.48      0.31      0.38     16738\n",
      "         FS       0.41      0.06      0.11      4206\n",
      "         FT       0.42      0.41      0.42     32338\n",
      "         IN       1.00      0.70      0.82      1641\n",
      "         KC       0.50      0.08      0.13      3367\n",
      "         KN       0.80      1.00      0.89      1784\n",
      "         PO       0.00      0.00      0.00       349\n",
      "         SC       0.54      0.15      0.23        47\n",
      "         SI       0.52      0.84      0.64     35234\n",
      "         SL       0.43      0.19      0.26     43897\n",
      "\n",
      "avg / total       0.46      0.48      0.42    286665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuarkarnad/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_metrics(bestridge, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model performed roughly the same as the test set. The model is really good at predicting Intentional Balls and Knuckleballs. It also can't predict an Ephesus pitch very well. However even casual fans can figure out when intentional balls are about to be thrown so this finding isn't very insightful. Some ideas I have are to drop features like team_id and maybe aggregate some of the outcome variables like the Two-Seam Fastball with the Four-Seam Fastball. I see a correlation with pitching choice and the pitches thrown in the game.  In the Random Forest model pitching and at bats were both very important features and both are related to length time played and pitches thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
